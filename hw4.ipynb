{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f525b9",
   "metadata": {},
   "source": [
    "# Training transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1790eb",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, GPT2Config, set_seed\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, Any, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa411bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PixelSequenceDataset(Dataset):\n",
    "    def __init__(self, data: List[List[int]], mode: str = \"train\"):\n",
    "        self.data = data\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Union[Tuple[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "        # Union - 多态，匹配多种类型\n",
    "        '''\n",
    "        train: return -> (input_ids, labels)\n",
    "        dev: return -> (input_ids, labels)\n",
    "        test: -> input_ids\n",
    "        '''\n",
    "        sequence = self.data[idx] # 拿出指定序号的色彩列\n",
    "        # 注意这里的transformer训练特点\n",
    "        if self.mode == \"train\":\n",
    "            input_ids = torch.tensor(sequence[:-1], dtype = torch.long) # 用来输入decoder的是最后一个之前的pixel\n",
    "            labels = torch.tensor(sequence[1:], dtype = torch.long) # 用来label的是除了第一个之外的label\n",
    "            # 因为这里输入和输出都是固定长度的，所以不需要什么起始和终止，也不需要tokenizer\n",
    "            return input_ids, labels\n",
    "        elif self.mode == \"dev\":\n",
    "            # 验证的话，后160像素用来验证\n",
    "            input_ids = torch.tensor(sequence[:-160], dtype=torch.long)\n",
    "            labels = torch.tensor(sequence[-160:], dtype=torch.long)\n",
    "            return input_ids, labels\n",
    "        elif self.mode == \"test\":\n",
    "            # test的话就全拿走\n",
    "            input_ids = torch.tensor(sequence, dtype=torch.long)\n",
    "            return input_ids\n",
    "\n",
    "        raise ValueError(f\"Invalid mode: {self.mode}. Choose from 'train', 'dev', or 'test'.\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169e42a",
   "metadata": {},
   "source": [
    "## download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416eccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pokemon dataset from Hugging Face Hub\n",
    "pokemon_dataset = load_dataset(\"lca0503/ml2025-hw4-pokemon\")\n",
    "# (index, 400, num_classes)\n",
    "\n",
    "# Load the colormap from Hugging Face Hub\n",
    "colormap = list(load_dataset(\"lca0503/ml2025-hw4-colormap\")[\"train\"][\"color\"])\n",
    "# colarmap 是序号和颜色的对应表 (colar_classes, 3(rgb))\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = len(colormap)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16\n",
    "\n",
    "# === Prepare Dataset and DataLoader for Training ===\n",
    "train_dataset: PixelSequenceDataset = PixelSequenceDataset(\n",
    "    pokemon_dataset[\"train\"][\"pixel_color\"], mode=\"train\"\n",
    ")\n",
    "train_dataloader: DataLoader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# === Prepare Dataset and DataLoader for Validation ===\n",
    "dev_dataset: PixelSequenceDataset = PixelSequenceDataset(\n",
    "    pokemon_dataset[\"dev\"][\"pixel_color\"], mode=\"dev\"\n",
    ")\n",
    "dev_dataloader: DataLoader = DataLoader(\n",
    "    dev_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# === Prepare Dataset and DataLoader for Testing ===\n",
    "test_dataset: PixelSequenceDataset = PixelSequenceDataset(\n",
    "    pokemon_dataset[\"test\"][\"pixel_color\"], mode=\"test\"\n",
    ")\n",
    "test_dataloader: DataLoader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec28030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_image(pixel_color: List[int], colormap: List[List[int]]) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Converts a list of pixel indices into a 20x20 RGB image using a colormap.\n",
    "\n",
    "    Args:\n",
    "        pixel_color (List[int]): A list of pixel indices representing colors.\n",
    "        colormap (List[List[int]]): A list where each index maps to an RGB color [R, G, B].\n",
    "\n",
    "    Returns:\n",
    "        Image.Image: A PIL Image object representing the reconstructed image.\n",
    "    \"\"\"\n",
    "    # Ensure the pixel_color list has at least 400 elements (pad with 0s if needed)\n",
    "    while len(pixel_color) < 400:\n",
    "        pixel_color.append(0)\n",
    "\n",
    "    # Map pixel indices to actual RGB colors using the colormap\n",
    "    pixel_data = [colormap[pixel] for pixel in pixel_color]\n",
    "\n",
    "    # Convert to numpy array and reshape to 20x20x3 (RGB image)\n",
    "    image_array = np.array(pixel_data, dtype=np.uint8).reshape(20, 20, 3)\n",
    "\n",
    "    # Create a PIL Image from the array\n",
    "    image = Image.fromarray(image_array)\n",
    "\n",
    "    return image\n",
    "\n",
    "def show_images(images: List[Image.Image]) -> None:\n",
    "    \"\"\"\n",
    "    Displays a grid of up to 96 images using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        images (List[Image.Image]): A list of PIL Image objects to display.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    num_images = min(96, len(images))  # Limit to 96 images\n",
    "\n",
    "    # Set up the figure size and grid layout (6 rows, 16 columns)\n",
    "    fig, axes = plt.subplots(6, 16, figsize=(16, 6))\n",
    "    axes = axes.flatten()  # Flatten to make iteration easier\n",
    "    # 最多输出96张\n",
    "\n",
    "    # Loop through images and display each one in the grid\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < num_images:\n",
    "            ax.imshow(images[i])\n",
    "            ax.axis('off')  # Hide axis\n",
    "        else:\n",
    "            ax.axis('off')  # Hide unused subplots\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train images\n",
    "train_images = [pixel_to_image(data[\"pixel_color\"], colormap) for data in pokemon_dataset[\"train\"]]\n",
    "show_images(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test images\n",
    "test_images = [pixel_to_image(data[\"pixel_color\"], colormap) for data in pokemon_dataset[\"test\"]]\n",
    "show_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a988861",
   "metadata": {},
   "source": [
    "## prepare model\n",
    "\n",
    "### Model Configuration\n",
    "Here, we define the model configuration, including the architecture and key hyperparameters such as the number of attention heads, layers, embedding size, and more.\n",
    "*   Hint 1: Adjust hyperparameters here for improved performance.\n",
    "*   Hint 2: Experiment with different model architectures, such as Llama, Mistral, or Qwen, to enhance performance.\n",
    "  * [LlamaConfig](https://huggingface.co/docs/transformers/model_doc/llama#transformers.LlamaConfig)\n",
    "  * [MistralConfig](https://huggingface.co/docs/transformers/model_doc/mistral#transformers.MistralConfig)\n",
    "  * [Qwen2Config](https://huggingface.co/docs/transformers/model_doc/qwen2#transformers.Qwen2Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e382492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GPT-2 model configuration as a dictionary\n",
    "gpt2_config = {\n",
    "    \"activation_function\": \"gelu_new\",    # Activation function used in the model\n",
    "    \"architectures\": [\"GPT2LMHeadModel\"],  # Specifies the model type\n",
    "    \"attn_pdrop\": 0.1,            # Dropout rate for attention layers\n",
    "    \"embd_pdrop\": 0.1,            # Dropout rate for embeddings\n",
    "    \"initializer_range\": 0.02,        # Standard deviation for weight initialization\n",
    "    \"layer_norm_epsilon\": 1e-05,       # Small constant to improve numerical stability in layer norm\n",
    "    \"model_type\": \"gpt2\",           # Type of model\n",
    "    \"n_ctx\": 128,               # Context size (maximum sequence length)\n",
    "    \"n_embd\": 64,              # Embedding size\n",
    "    \"n_head\": 2,               # Number of attention heads\n",
    "    \"n_layer\": 2,              # Number of transformer layers\n",
    "    \"n_positions\": 400,           # Maximum number of token positions\n",
    "    \"resid_pdrop\": 0.1,           # Dropout rate for residual connections\n",
    "    \"vocab_size\": num_classes,       # Number of unique tokens in vocabulary\n",
    "    \"pad_token_id\": None,          # Padding token ID (None means no padding token)\n",
    "    \"eos_token_id\": None,          # End-of-sequence token ID (None means not explicitly defined)\n",
    "}\n",
    "\n",
    "# Load GPT-2 model configuration from dictionary\n",
    "config = GPT2Config.from_dict(gpt2_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea93d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model using the configuration defined above\n",
    "model = AutoModelForCausalLM.from_config(config)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416e372",
   "metadata": {},
   "source": [
    "## Train and Inference\n",
    "\n",
    "### Training Arguments\n",
    "Here, we define the number of epochs for training, the learning rate, the optimizer, and the loss function.\n",
    "*   Hint 3: Adjust the number of epochs and learning rate here to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "epochs = 50                                      # Number of training epochs\n",
    "learning_rate = 1e-3                                 # Learning rate for optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")     # Check if CUDA is available for GPU\n",
    "save_dir = \"checkpoints\"                               # Directory to save model checkpoints\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()                          # Loss function for classification tasks\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.1) # AdamW optimizer with weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: torch.nn.Module, optimizer: torch.optim.Optimizer, epoch: int, loss: float, save_dir: str, filename: str = \"best_model.pth\") -> None:\n",
    "    \"\"\"\n",
    "    Saves the model state, optimizer state, current epoch, and loss to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The PyTorch model to be saved.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer whose state will be saved.\n",
    "        epoch (int): The current epoch number (used for checkpointing).\n",
    "        loss (float): The current loss value to track model performance.\n",
    "        save_dir (str): The directory where the model checkpoint will be saved.\n",
    "        filename (str, optional): The name of the file to save the model. Defaults to \"best_model.pth\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Construct the full path for saving the model checkpoint\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    # Save the model, optimizer state, and additional metadata (epoch and loss)\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,                # Save epoch + 1 for easier tracking\n",
    "        'model_state_dict': model.state_dict(),       # Save model weights\n",
    "        'optimizer_state_dict': optimizer.state_dict(),  # Save optimizer state (important for resuming training)\n",
    "        'loss': loss                     # Save the current loss value\n",
    "    }, save_path)\n",
    "\n",
    "    # Print a confirmation message indicating the model has been saved\n",
    "    print(f\"Model saved at {save_path} (Loss: {loss:.4f}, Epoch: {epoch + 1})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccb05f",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "We save the checkpoint with the lowest training loss since validation set reconstruction accuracy doesn't directly reflect the model's image generation quality.\n",
    "*   Hint 4: Train a classifier to check if an image looks like a Pokémon or not. (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35f32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50: 100%|██████████| 40/40 [00:00<00:00, 41.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Reconstruction Accuracy: 0.3078\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4755, Epoch: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/50: 100%|██████████| 40/40 [00:00<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 1.4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Reconstruction Accuracy: 0.3329\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4650, Epoch: 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/50: 100%|██████████| 40/40 [00:00<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 1.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Reconstruction Accuracy: 0.3189\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4609, Epoch: 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/50: 100%|██████████| 40/40 [00:00<00:00, 44.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 1.4569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Reconstruction Accuracy: 0.3291\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4569, Epoch: 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/50: 100%|██████████| 40/40 [00:00<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 1.4531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Reconstruction Accuracy: 0.2980\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4531, Epoch: 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/50: 100%|██████████| 40/40 [00:00<00:00, 43.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 1.4488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Reconstruction Accuracy: 0.2934\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4488, Epoch: 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/50: 100%|██████████| 40/40 [00:00<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 1.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Reconstruction Accuracy: 0.3274\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4475, Epoch: 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/50: 100%|██████████| 40/40 [00:00<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 1.4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Reconstruction Accuracy: 0.3239\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4427, Epoch: 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/50: 100%|██████████| 40/40 [00:00<00:00, 45.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 1.4395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Reconstruction Accuracy: 0.3095\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4395, Epoch: 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/50: 100%|██████████| 40/40 [00:00<00:00, 42.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 1.4399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Reconstruction Accuracy: 0.3264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/50: 100%|██████████| 40/40 [00:00<00:00, 43.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 1.4318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Reconstruction Accuracy: 0.3441\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4318, Epoch: 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/50: 100%|██████████| 40/40 [00:00<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 1.4273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Reconstruction Accuracy: 0.3125\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4273, Epoch: 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/50: 100%|██████████| 40/40 [00:00<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 1.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Reconstruction Accuracy: 0.3577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/50: 100%|██████████| 40/40 [00:00<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 1.4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Reconstruction Accuracy: 0.2975\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4268, Epoch: 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/50: 100%|██████████| 40/40 [00:01<00:00, 39.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 1.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Reconstruction Accuracy: 0.3272\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4221, Epoch: 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/50: 100%|██████████| 40/40 [00:01<00:00, 36.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 1.4196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Reconstruction Accuracy: 0.3290\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4196, Epoch: 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/50: 100%|██████████| 40/40 [00:01<00:00, 35.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 1.4161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Reconstruction Accuracy: 0.3164\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4161, Epoch: 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/50: 100%|██████████| 40/40 [00:01<00:00, 35.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 1.4109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Reconstruction Accuracy: 0.3055\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4109, Epoch: 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/50: 100%|██████████| 40/40 [00:01<00:00, 35.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 1.4103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Reconstruction Accuracy: 0.3201\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4103, Epoch: 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/50: 100%|██████████| 40/40 [00:01<00:00, 35.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 1.4054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Reconstruction Accuracy: 0.3189\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4054, Epoch: 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/50: 100%|██████████| 40/40 [00:01<00:00, 35.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 1.4042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Reconstruction Accuracy: 0.2882\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.4042, Epoch: 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/50: 100%|██████████| 40/40 [00:01<00:00, 35.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 1.4056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Reconstruction Accuracy: 0.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/50: 100%|██████████| 40/40 [00:00<00:00, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 1.3995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Reconstruction Accuracy: 0.3168\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.3995, Epoch: 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/50: 100%|██████████| 40/40 [00:00<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 1.3992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Reconstruction Accuracy: 0.2957\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.3992, Epoch: 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/50: 100%|██████████| 40/40 [00:00<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 1.3987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Reconstruction Accuracy: 0.3231\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.3987, Epoch: 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/50: 100%|██████████| 40/40 [00:00<00:00, 43.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 1.3945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Reconstruction Accuracy: 0.3259\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.3945, Epoch: 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/50: 100%|██████████| 40/40 [00:00<00:00, 44.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 1.3926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Reconstruction Accuracy: 0.2769\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.3926, Epoch: 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/50: 100%|██████████| 40/40 [00:00<00:00, 43.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 1.3877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Reconstruction Accuracy: 0.2775\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.3877, Epoch: 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/50: 100%|██████████| 40/40 [00:00<00:00, 44.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 1.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Reconstruction Accuracy: 0.3395\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.3845, Epoch: 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/50: 100%|██████████| 40/40 [00:00<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 1.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Reconstruction Accuracy: 0.3191\n",
      "Model saved at checkpoints/best_model.pth (Loss: 1.3842, Epoch: 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/50: 100%|██████████| 40/40 [00:00<00:00, 44.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 1.3821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  80%|████████  | 4/5 [00:01<00:00,  2.72it/s]"
     ]
    }
   ],
   "source": [
    "# Create save directory if it doesn't exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# Initialize best loss as positive infinity for comparison during model checkpointing\n",
    "best_loss: float = float('inf')\n",
    "# Move model to the appropriate device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0  # Initialize the epoch loss\n",
    "\n",
    "    # Iterate over training data batches\n",
    "    for input_ids, labels in tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{epochs}\"):\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device)  # Move data to the same device as the model\n",
    "\n",
    "        # Forward pass through the model to get logits (output probabilities)\n",
    "        outputs = model(input_ids=input_ids).logits.view(-1, config.vocab_size)\n",
    "        labels = labels.view(-1)  # Flatten labels to match logits shape\n",
    "\n",
    "        # Calculate loss using CrossEntropyLoss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation and optimizer step\n",
    "        optimizer.zero_grad()  # Reset gradients to zero\n",
    "        loss.backward()     # Compute gradients\n",
    "        optimizer.step()     # Update model weights\n",
    "\n",
    "        # Accumulate the loss for the epoch\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Compute average epoch loss\n",
    "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluation Loop (Validation)\n",
    "    model.eval()      # Set the model to evaluation mode (disables dropout, etc.)\n",
    "    total_accuracy = 0  # Initialize total accuracy\n",
    "    num_batches = 0   # Initialize batch counter\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        # Iterate over validation data batches\n",
    "        for inputs, labels in tqdm(dev_dataloader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move validation data to device\n",
    "            attention_mask = torch.ones_like(inputs)          # Attention mask to ensure valid token positions\n",
    "\n",
    "            # Perform batch inference using the model\n",
    "            generated_outputs = model.generate(inputs, attention_mask=attention_mask, max_length=400)\n",
    "\n",
    "            # Extract the last 160 tokens from generated outputs and labels\n",
    "            generated_outputs = generated_outputs[:, -160:]\n",
    "\n",
    "            # Calculate accuracy for the batch\n",
    "            accuracy = (generated_outputs == labels).float().mean().item()\n",
    "            total_accuracy += accuracy\n",
    "            num_batches += 1\n",
    "\n",
    "    # Compute average reconstruction accuracy for the epoch\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Reconstruction Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "    # If the current epoch loss is better (lower) than the best loss, save the model\n",
    "    if avg_epoch_loss < best_loss:\n",
    "        best_loss = avg_epoch_loss                   # Update best loss\n",
    "        save_model(model, optimizer, epoch, best_loss, save_dir)  # Save the model with the best loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from the saved checkpoint\n",
    "best_model_path = os.path.join(save_dir, \"best_model.pth\")              # Path to the best model checkpoint\n",
    "checkpoint = torch.load(best_model_path, weights_only=True, map_location=device)  # Load checkpoint from the file\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])                  # Load the model weights from checkpoint\n",
    "model.eval()                                        # Set the model to evaluation mode (disables dropout, etc.)\n",
    "\n",
    "# Testing Loop with Batch Inference\n",
    "results: list = []  # List to store the generated sequences from the model\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations for inference\n",
    "    # Iterate over test data in batches\n",
    "    for inputs in tqdm(test_dataloader, desc=\"Generating Outputs\"):\n",
    "        inputs = inputs.to(device)         # Move model to the appropriate device (GPU or CPU)\n",
    "        attention_mask = torch.ones_like(inputs)  # Attention mask (ensure valid token positions)\n",
    "\n",
    "        # Generate predictions for the entire batch\n",
    "        generated_outputs = model.generate(inputs, attention_mask=attention_mask, max_length=400)\n",
    "\n",
    "        # Convert batch outputs to a list and append to results\n",
    "        batch_results = generated_outputs.cpu().numpy().tolist()\n",
    "        results.extend(batch_results)  # Extend the results list with batch results\n",
    "\n",
    "# Save the results to a file\n",
    "output_file: str = \"reconstructed_results.txt\"  # File to save the output sequences\n",
    "with open(output_file, \"w\") as f:\n",
    "    # Write each sequence to the file\n",
    "    for seq in results:\n",
    "        f.write(\" \".join(map(str, seq)) + \"\\n\")\n",
    "\n",
    "print(f\"Reconstructed results saved to {output_file}\")  # Confirmation message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize generated test images\n",
    "predicted_images = [pixel_to_image(sequence, colormap) for sequence in results]\n",
    "show_images(predicted_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhy2025hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
